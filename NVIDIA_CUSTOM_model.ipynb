{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ducki-my-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GojswBu3jEht"
      },
      "source": [
        "import cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\r\n",
        "\r\n",
        "SHAPE = (160, 320, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou__rJhOuqQj"
      },
      "source": [
        "# Function that will used in image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qh48cyUjHjx"
      },
      "source": [
        "def crop_resize(image, result_shape = (160, 320)):\r\n",
        "    preprocessed_image = image[180::]\r\n",
        "    preprocessed_image = cv2.resize(preprocessed_image, result_shape, cv2.INTER_AREA)\r\n",
        "    return preprocessed_image\r\n",
        "\r\n",
        "def random_brightness(image):\r\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\r\n",
        "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\r\n",
        "    hsv[:,:,2] =  hsv[:,:,2] * ratio\r\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\r\n",
        "\r\n",
        "\r\n",
        "def random_shadow(image):\r\n",
        "    h, w = image.shape[:-1]\r\n",
        "    x1, y1 = w * np.random.rand(), 0\r\n",
        "    x2, y2 = w * np.random.rand(), h\r\n",
        "    xm, ym = np.mgrid[0:h, 0:w]\r\n",
        "\r\n",
        "    mask = np.zeros_like(image[:, :, 1])\r\n",
        "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\r\n",
        "\r\n",
        "    cond = mask == np.random.randint(2)\r\n",
        "    s_ratio = np.random.uniform(low=0.2, high=0.5)\r\n",
        "\r\n",
        "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\r\n",
        "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\r\n",
        "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\r\n",
        "\r\n",
        "\r\n",
        "def random_flip(image, angle):\r\n",
        "    if np.random.rand() < 0.5:\r\n",
        "        image = cv2.flip(image, 1)\r\n",
        "        angle = -angle\r\n",
        "    return image, angle\r\n",
        "\r\n",
        "\r\n",
        "def random_salt_and_pepper(image):\r\n",
        "    if(np.random.rand() < .10):\r\n",
        "        return image\r\n",
        "    row,col,ch = image.shape\r\n",
        "    s_vs_p = 0.5\r\n",
        "    amount = 0.02\r\n",
        "    out = np.copy(image)\r\n",
        "    # Salt mode\r\n",
        "    num_salt = np.ceil(amount * image.size * s_vs_p)\r\n",
        "    coords = [np.random.randint(0, i - 1, int(num_salt))\r\n",
        "            for i in image.shape]\r\n",
        "    out[coords] = 1\r\n",
        "\r\n",
        "    # Pepper mode\r\n",
        "    num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\r\n",
        "    coords = [np.random.randint(0, i - 1, int(num_pepper))\r\n",
        "            for i in image.shape]\r\n",
        "    out[coords] = 0\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr_NmZMHu0oV"
      },
      "source": [
        "# To Convert action to one hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBsmqQ8KMDcN"
      },
      "source": [
        "def action_to_one_hot(action):\n",
        "    index = int(action + 1)\n",
        "    res = np.zeros(3, dtype=np.int)\n",
        "    res[index] = 1\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUKjB-qu_aO"
      },
      "source": [
        "# Data generator function which is used for image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeqxLtWzjJ8x"
      },
      "source": [
        "def data_generator(directory, batch_size, image_pre_path = \".\"):\r\n",
        "    \r\n",
        "\r\n",
        "    df = pd.read_csv(directory)\r\n",
        "    samples_len = len(df)\r\n",
        "    \r\n",
        "    while True:\r\n",
        "        train_x = []\r\n",
        "        train_y = []\r\n",
        "        for _ in range(batch_size):\r\n",
        "           \r\n",
        "            sample_index = np.random.randint(samples_len)\r\n",
        "            image_file_name = df.loc[sample_index, \"image_name\"]\r\n",
        "            \r\n",
        "            #action_x =  df.loc[sample_index, \"x\"]\r\n",
        "            action_y =  df.loc[sample_index, \"y_button\"]\r\n",
        "\r\n",
        "            image = cv2.imread(f\"{image_pre_path}/{image_file_name}\")\r\n",
        "            \r\n",
        "            image = crop_resize(image)\r\n",
        "            image = random_brightness(image)\r\n",
        "            image = random_shadow(image)\r\n",
        "            image, action_y = random_flip(image, action_y)\r\n",
        "            image = random_salt_and_pepper(image)\r\n",
        "            \r\n",
        "            train_x.append(image)\r\n",
        "            train_y.append(action_to_one_hot(action_y))\r\n",
        "\r\n",
        "        train_x = np.array(train_x)\r\n",
        "        train_y = np.array(train_y)\r\n",
        "        yield train_x.reshape((-1, SHAPE[0], SHAPE[1], SHAPE[2])), train_y.reshape((-1, 3))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axQi5mjHvLZH"
      },
      "source": [
        "# Customized Nvidia Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1jt8IY-jMNE"
      },
      "source": [
        "def build_model():\r\n",
        "    model=Sequential()\r\n",
        "    model.add(Lambda(lambda x: x/255.,input_shape=(160,320,3)))\r\n",
        "    #ELU(Exponential linear unit) function takes care of the Vanishing gradient problem.\r\n",
        "    model.add(Conv2D(24,(5,5),activation=\"elu\",strides=(2,2)))\r\n",
        "    model.add(Conv2D(36,(5,5),activation=\"elu\",strides=(2,2)))\r\n",
        "    model.add(Conv2D(48,(5,5),activation=\"elu\",strides=(2,2)))\r\n",
        "    model.add(Conv2D(64,(5,5),activation=\"elu\"))\r\n",
        "    model.add(Conv2D(64,(5,5),activation=\"elu\"))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(100,activation=\"elu\"))\r\n",
        "    model.add(Dense(50,activation=\"elu\"))\r\n",
        "    model.add(Dense(10,activation=\"elu\"))\r\n",
        "    model.add(Dense(3,activation=\"softmax\"))\r\n",
        "\r\n",
        "\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44NVf4hSjOAx",
        "outputId": "af3eeb32-a00e-4ba6-a2a6-a3f5a5eedefe"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              (None, 160, 320, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 78, 158, 24)       1824      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 37, 77, 36)        21636     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 17, 37, 48)        43248     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 33, 64)        76864     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 29, 64)         102464    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 9, 29, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16704)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               1670500   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 1,922,129\n",
            "Trainable params: 1,922,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpyLLWdLvQbC"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRFAEzpFjTO0"
      },
      "source": [
        "def train(model, csv_path):\r\n",
        "\t#path verinin kaydedildiği csv yi gösterecek\r\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001),metrics=[\"accuracy\"])\r\n",
        "   \r\n",
        "    #####\r\n",
        "    #path olarak yazılan yere uygun adresi ver\r\n",
        "    #####\r\n",
        "\tcheckpoint = ModelCheckpoint(\"/content/drive/MyDrive/models (1)/bin_v{epoch:02d}.hdf5\", verbose=1) #val_acc yok ondan val_loss\r\n",
        "\r\n",
        "\t\"\"\"\r\n",
        "\tfit_generator(object, generator, steps_per_epoch, epochs = 1,\r\n",
        "\t\tverbose = getOption(\"keras.fit_verbose\", default = 1),\r\n",
        "\t\tcallbacks = NULL, view_metrics = getOption(\"keras.view_metrics\",\r\n",
        "\t\tdefault = \"auto\"), validation_data = NULL, validation_steps = NULL,\r\n",
        "\t\tclass_weight = NULL, max_queue_size = 10, workers = 1,\r\n",
        "\t\tinitial_epoch = 0)\r\n",
        "\t\"\"\"\r\n",
        "    #fotolar da images klasörünün içinde olacak şekide yazdım ama \r\n",
        "    #fotolar drive'a yüklenirse (ki daha kolay olur) google drive colab'a bağlanmalı ve\r\n",
        "    #image_pre_path argumanı driveda fotoların olduğu yol olmalı\r\n",
        "\tmodel.fit_generator(data_generator(csv_path, 32, image_pre_path = \"/content/drive/MyDrive/duckie-town/images\"),\r\n",
        "\t\t\t\t\t\tsteps_per_epoch = 10000,\r\n",
        "\t\t\t\t\t\tepochs = 1,\r\n",
        "\t\t\t\t\t\tvalidation_data=data_generator(csv_path, 100, image_pre_path = \"/content/drive/MyDrive/duckie-town/images\"),\r\n",
        "\t\t\t\t\t\tvalidation_steps = 5,\r\n",
        "\t\t\t\t\t\tcallbacks=[TensorBoard(log_dir='/content/drive/MyDrive/models (1)/', histogram_freq=0, write_graph=False), checkpoint ])\r\n",
        " \r\n",
        "    #####\r\n",
        "    #path olarak yazılan yere uygun adresi ver\r\n",
        "    #####\r\n",
        "\tmodel.save(\"/content/drive/MyDrive/models (1)/trio.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDLYUrMSjU8i",
        "outputId": "c9d25ed9-c68f-4f2b-ed91-11d71db6fecd"
      },
      "source": [
        "train(model, \"/content/drive/MyDrive/duckie-town/data/all.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5571s 557ms/step - loss: 0.3121 - accuracy: 0.8639 - val_loss: 0.0668 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/models (1)/bin_v01.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IYxdF8WLCOi"
      },
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/models (1)/trio_weights_180_1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lesOPAGXKleS",
        "outputId": "b9f1c2a2-c8c7-4d9f-a2bb-60e2a0da2799"
      },
      "source": [
        "train(model, \"/content/drive/MyDrive/duckie-town/data/all.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4242s 424ms/step - loss: 0.0608 - accuracy: 0.9739 - val_loss: 0.0186 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/models (1)/bin_v01.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NJ868cGLGB5"
      },
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/models (1)/trio_weights_180_2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i3ZDISIKlcD",
        "outputId": "4abbf450-a928-4bc7-97d0-bad9ce73b8b3"
      },
      "source": [
        "train(model, \"/content/drive/MyDrive/duckie-town/data/all.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4195s 419ms/step - loss: 0.0336 - accuracy: 0.9858 - val_loss: 0.0070 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/models (1)/bin_v01.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANKd4mcHLGgC"
      },
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/models (1)/trio_weights_180_3.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etAj7sw5KlaD"
      },
      "source": [
        "train(model, \"/content/drive/MyDrive/duckie-town/data/all.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78bE86ZOLHCQ"
      },
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/models (1)/trio_weights_180_3.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}